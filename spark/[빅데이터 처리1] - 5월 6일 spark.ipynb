{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7c4811c",
   "metadata": {},
   "source": [
    "# [빅데이터 처리1] - 5월 6일 spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7c6a20",
   "metadata": {},
   "source": [
    "# - spark vs 일반환경 소수 만드는 함수로 시간 비교해보기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a321258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff5af522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2731def",
   "metadata": {},
   "outputs": [],
   "source": [
    "#스파크 접속 \n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3b10fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-VH8V6JM:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c030279",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "039db2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([i for i in range(3,MAX+1)],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "328d9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prime(num):\n",
    "    isPrime = True\n",
    "    \n",
    "    for index in range(2,num):\n",
    "    \n",
    "        if num % index == 0:\n",
    "            isPrime = False\n",
    "            break\n",
    "    \n",
    "    if isPrime == True:\n",
    "        return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a539423",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "prime_list = rdd.map(get_prime).collect()\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cbb18cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간= 13.86107850074768\n"
     ]
    }
   ],
   "source": [
    "print(\"소요시간=\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf51c537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f89e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark 안쓸때 ??? -> 시간 더 걸림 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf0f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "657e3b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c858e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX =100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bc3e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst01 = [i for i in range(3,MAX+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56012501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prime(num):\n",
    "    isPrime = True\n",
    "    \n",
    "    for index in range(2,num):\n",
    "        \n",
    "        if num % index == 0:\n",
    "            isPrime = False\n",
    "            break \n",
    "   \n",
    "    if isPrime == True:\n",
    "        return num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb00504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prime(num):\n",
    "    isPrime = True\n",
    "    \n",
    "    for index in range(2,num):\n",
    "        \n",
    "        if num % index == 0:\n",
    "            isPrime = False\n",
    "            break \n",
    "   \n",
    "        else :\n",
    "            isPrime == True\n",
    "            \n",
    "        return num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a3f4dbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(get_prime(21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23f36155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간 = 32.5168981552124\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "prime_list = list(map(get_prime, lst01))\n",
    "\n",
    "end =time.time()\n",
    "\n",
    "print(\"소요시간 =\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a07351",
   "metadata": {},
   "source": [
    "## - spark 이용한 Decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "798c8767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dtreeviz[pyspark]\n",
      "  Downloading dtreeviz-1.3.tar.gz (60 kB)\n",
      "Collecting graphviz>=0.9\n",
      "  Using cached graphviz-0.16-py2.py3-none-any.whl (19 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-win_amd64.whl (8.7 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\envs\\spark_env\\lib\\site-packages (from dtreeviz[pyspark]) (1.19.5)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp36-cp36m-win_amd64.whl (6.8 MB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.3.4-cp36-cp36m-win_amd64.whl (8.5 MB)\n",
      "Collecting colour\n",
      "  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pytest\n",
      "  Downloading pytest-6.2.4-py3-none-any.whl (280 kB)\n",
      "Requirement already satisfied: pyspark in .\\spark\\python (from dtreeviz[pyspark]) (2.4.7)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\admin\\anaconda3\\envs\\spark_env\\lib\\site-packages (from matplotlib->dtreeviz[pyspark]) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\admin\\anaconda3\\envs\\spark_env\\lib\\site-packages (from matplotlib->dtreeviz[pyspark]) (2.8.1)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.2.0-cp36-cp36m-win_amd64.whl (2.2 MB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp36-cp36m-win_amd64.whl (51 kB)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\anaconda3\\envs\\spark_env\\lib\\site-packages (from cycler>=0.10->matplotlib->dtreeviz[pyspark]) (1.15.0)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting py4j==0.10.7\n",
      "  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.10.0-py2.py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\admin\\anaconda3\\envs\\spark_env\\lib\\site-packages (from pytest->dtreeviz[pyspark]) (20.3.0)\n",
      "Collecting pluggy<1.0.0a1,>=0.12\n",
      "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting atomicwrites>=1.0\n",
      "  Downloading atomicwrites-1.4.0-py2.py3-none-any.whl (6.8 kB)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\envs\\spark_env\\lib\\site-packages (from pytest->dtreeviz[pyspark]) (20.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\spark_env\\lib\\site-packages (from pytest->dtreeviz[pyspark]) (0.4.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\admin\\anaconda3\\envs\\spark_env\\lib\\site-packages (from pytest->dtreeviz[pyspark]) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\admin\\anaconda3\\envs\\spark_env\\lib\\site-packages (from importlib-metadata>=0.12->pytest->dtreeviz[pyspark]) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\admin\\anaconda3\\envs\\spark_env\\lib\\site-packages (from importlib-metadata>=0.12->pytest->dtreeviz[pyspark]) (3.4.1)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: dtreeviz\n",
      "  Building wheel for dtreeviz (setup.py): started\n",
      "  Building wheel for dtreeviz (setup.py): finished with status 'done'\n",
      "  Created wheel for dtreeviz: filename=dtreeviz-1.3-py3-none-any.whl size=66638 sha256=f2f4126bd8107a229f11632cf71dd25804e61dc254c5e4e01ebba4b47f391e9e\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\37\\35\\0b\\90a432df982480b9285addd983d37ab7e53ba75481047b7310\n",
      "Successfully built dtreeviz\n",
      "Installing collected packages: toml, threadpoolctl, scipy, pytz, py, pluggy, pillow, kiwisolver, joblib, iniconfig, cycler, atomicwrites, scikit-learn, pytest, py4j, pandas, matplotlib, graphviz, colour, dtreeviz\n",
      "Successfully installed atomicwrites-1.4.0 colour-0.1.5 cycler-0.10.0 dtreeviz-1.3 graphviz-0.16 iniconfig-1.1.1 joblib-1.0.1 kiwisolver-1.3.1 matplotlib-3.3.4 pandas-1.1.5 pillow-8.2.0 pluggy-0.13.1 py-1.10.0 py4j-0.10.7 pytest-6.2.4 pytz-2021.1 scikit-learn-0.24.2 scipy-1.5.4 threadpoolctl-2.1.0 toml-0.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install dtreeviz[pyspark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88592aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fc9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) csv파일 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d827aa90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Outlook: string, Temperature: string, Humidity: string, Wind: string, PlayTennis: string]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv(\"playtennis.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a31e2f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"playtennis.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3987d569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e2c54d68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-1db680494cdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Outlook\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Rain\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutlook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "df[\"Outlook\"].replace(\"Rain\",2,inplace=True)\n",
    "df.Outlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "756e94e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------+------+----------+\n",
      "| Outlook|Temperature|Humidity|  Wind|PlayTennis|\n",
      "+--------+-----------+--------+------+----------+\n",
      "|   Sunny|        Hot|    High|  Weak|        No|\n",
      "|   Sunny|        Hot|    High|Strong|        No|\n",
      "|Overcast|        Hot|    High|  Weak|       Yes|\n",
      "|    Rain|       Mild|    High|  Weak|       Yes|\n",
      "|    Rain|       Cool|  Normal|  Weak|       Yes|\n",
      "|    Rain|       Cool|  Normal|Strong|        No|\n",
      "|Overcast|       Cool|  Normal|Strong|       Yes|\n",
      "|   Sunny|       Mild|    High|  Weak|        No|\n",
      "|   Sunny|       Cool|  Normal|  Weak|       Yes|\n",
      "|    Rain|       Mild|  Normal|  Weak|       Yes|\n",
      "|   Sunny|       Mild|  Normal|Strong|       Yes|\n",
      "|Overcast|       Mild|    High|Strong|       Yes|\n",
      "|Overcast|        Hot|  Normal|  Weak|       Yes|\n",
      "|    Rain|       Mild|    High|Strong|        No|\n",
      "+--------+-----------+--------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()            #아까도 얘기했지만 글씨 있으면 안되잖아.숫자로 바꾸라구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3091f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) dataframe의 각 블록을 돌아 다니면서 컬럼값 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c7f4c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "87e39ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.withColumn(\"Outlook\",F.when(F.col(\"Outlook\")==\"Sunny\",0).otherwise(F.col(\"Outlook\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "aff9c4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------+------+----------+\n",
      "| Outlook|Temperature|Humidity|  Wind|PlayTennis|\n",
      "+--------+-----------+--------+------+----------+\n",
      "|       0|        Hot|    High|  Weak|        No|\n",
      "|       0|        Hot|    High|Strong|        No|\n",
      "|Overcast|        Hot|    High|  Weak|       Yes|\n",
      "|    Rain|       Mild|    High|  Weak|       Yes|\n",
      "|    Rain|       Cool|  Normal|  Weak|       Yes|\n",
      "|    Rain|       Cool|  Normal|Strong|        No|\n",
      "|Overcast|       Cool|  Normal|Strong|       Yes|\n",
      "|       0|       Mild|    High|  Weak|        No|\n",
      "|       0|       Cool|  Normal|  Weak|       Yes|\n",
      "|    Rain|       Mild|  Normal|  Weak|       Yes|\n",
      "|       0|       Mild|  Normal|Strong|       Yes|\n",
      "|Overcast|       Mild|    High|Strong|       Yes|\n",
      "|Overcast|        Hot|  Normal|  Weak|       Yes|\n",
      "|    Rain|       Mild|    High|Strong|        No|\n",
      "+--------+-----------+--------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "33cf020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Outlook\",F.when(F.col(\"Outlook\")==\"Overcast\",1).otherwise(F.col(\"Outlook\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "83d4e969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+------+----------+\n",
      "|Outlook|Temperature|Humidity|  Wind|PlayTennis|\n",
      "+-------+-----------+--------+------+----------+\n",
      "|      0|        Hot|    High|  Weak|        No|\n",
      "|      0|        Hot|    High|Strong|        No|\n",
      "|      1|        Hot|    High|  Weak|       Yes|\n",
      "|   Rain|       Mild|    High|  Weak|       Yes|\n",
      "|   Rain|       Cool|  Normal|  Weak|       Yes|\n",
      "|   Rain|       Cool|  Normal|Strong|        No|\n",
      "|      1|       Cool|  Normal|Strong|       Yes|\n",
      "|      0|       Mild|    High|  Weak|        No|\n",
      "|      0|       Cool|  Normal|  Weak|       Yes|\n",
      "|   Rain|       Mild|  Normal|  Weak|       Yes|\n",
      "|      0|       Mild|  Normal|Strong|       Yes|\n",
      "|      1|       Mild|    High|Strong|       Yes|\n",
      "|      1|        Hot|  Normal|  Weak|       Yes|\n",
      "|   Rain|       Mild|    High|Strong|        No|\n",
      "+-------+-----------+--------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "987b0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Outlook\",F.when(F.col(\"Outlook\")==\"Rain\",2).otherwise(F.col(\"Outlook\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0f237245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+------+----------+\n",
      "|Outlook|Temperature|Humidity|  Wind|PlayTennis|\n",
      "+-------+-----------+--------+------+----------+\n",
      "|      0|        Hot|    High|  Weak|        No|\n",
      "|      0|        Hot|    High|Strong|        No|\n",
      "|      1|        Hot|    High|  Weak|       Yes|\n",
      "|      2|       Mild|    High|  Weak|       Yes|\n",
      "|      2|       Cool|  Normal|  Weak|       Yes|\n",
      "|      2|       Cool|  Normal|Strong|        No|\n",
      "|      1|       Cool|  Normal|Strong|       Yes|\n",
      "|      0|       Mild|    High|  Weak|        No|\n",
      "|      0|       Cool|  Normal|  Weak|       Yes|\n",
      "|      2|       Mild|  Normal|  Weak|       Yes|\n",
      "|      0|       Mild|  Normal|Strong|       Yes|\n",
      "|      1|       Mild|    High|Strong|       Yes|\n",
      "|      1|        Hot|  Normal|  Weak|       Yes|\n",
      "|      2|       Mild|    High|Strong|        No|\n",
      "+-------+-----------+--------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "98d9c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Temperature\",F.when(F.col(\"Temperature\")==\"Hot\",0).otherwise(F.col(\"Temperature\")))\n",
    "df = df.withColumn(\"Temperature\",F.when(F.col(\"Temperature\")==\"Mild\",1).otherwise(F.col(\"Temperature\")))\n",
    "df = df.withColumn(\"Temperature\",F.when(F.col(\"Temperature\")==\"Cool\",2).otherwise(F.col(\"Temperature\")))\n",
    "\n",
    "df = df.withColumn(\"Humidity\", F.when(F.col(\"Humidity\")==\"High\", 0).otherwise(F.col(\"Humidity\")))\n",
    "df = df.withColumn(\"Humidity\", F.when(F.col(\"Humidity\")==\"Normal\", 1).otherwise(F.col(\"Humidity\")))\n",
    "\n",
    "df = df.withColumn(\"Wind\", F.when( F.col(\"Wind\")==\"Weak\",0).otherwise(F.col(\"Wind\")))\n",
    "df = df.withColumn(\"Wind\", F.when( F.col(\"Wind\")==\"Strong\",1).otherwise(F.col(\"Wind\")))\n",
    "\n",
    "df = df.withColumn(\"PlayTennis\", F.when( F.col(\"PlayTennis\")==\"No\",0).otherwise(F.col(\"PlayTennis\")))\n",
    "df = df.withColumn(\"PlayTennis\", F.when( F.col(\"PlayTennis\")==\"Yes\",1).otherwise(F.col(\"PlayTennis\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d6e5966f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+----+----------+\n",
      "|Outlook|Temperature|Humidity|Wind|PlayTennis|\n",
      "+-------+-----------+--------+----+----------+\n",
      "|      0|          0|       0|   0|         0|\n",
      "|      0|          0|       0|   1|         0|\n",
      "|      1|          0|       0|   0|         1|\n",
      "|      2|          1|       0|   0|         1|\n",
      "|      2|          2|       1|   0|         1|\n",
      "|      2|          2|       1|   1|         0|\n",
      "|      1|          2|       1|   1|         1|\n",
      "|      0|          1|       0|   0|         0|\n",
      "|      0|          2|       1|   0|         1|\n",
      "|      2|          1|       1|   0|         1|\n",
      "|      0|          1|       1|   1|         1|\n",
      "|      1|          1|       0|   1|         1|\n",
      "|      1|          0|       1|   0|         1|\n",
      "|      2|          1|       0|   1|         0|\n",
      "+-------+-----------+--------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "17fbdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) 컬럼 타입 수정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f3911d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Outlook,StringType,true),StructField(Temperature,StringType,true),StructField(Humidity,StringType,true),StructField(Wind,StringType,true),StructField(PlayTennis,StringType,true)))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2624c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Outlook\", df['Outlook'].cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "56ef73b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Outlook,IntegerType,true),StructField(Temperature,StringType,true),StructField(Humidity,StringType,true),StructField(Wind,StringType,true),StructField(PlayTennis,StringType,true)))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f6f7f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Temperature\",df['Temperature'].cast('int'))\n",
    "df = df.withColumn(\"Humidity\",df['Humidity'].cast('int'))\n",
    "df = df.withColumn(\"Wind\",df['Wind'].cast('int'))\n",
    "df = df.withColumn(\"PlayTennis\",df['PlayTennis'].cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "be751fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Outlook,IntegerType,true),StructField(Temperature,IntegerType,true),StructField(Humidity,IntegerType,true),StructField(Wind,IntegerType,true),StructField(PlayTennis,IntegerType,true)))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "be00db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Decision Tree \n",
    "# 독립변수 칸이 서로 다른 블록에 있을 수 있는데 같은 블록에 있어야함 => 한칸에 독립변수 다 때려 넣기 \n",
    "# : vector Assemble 138~139\n",
    "\n",
    "#train-test 분리 \n",
    "\n",
    "# decision tree 만들고 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171fae0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
